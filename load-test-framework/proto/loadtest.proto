syntax = "proto3";

package google.pubsub.loadtest;

import "google/protobuf/duration.proto";
import "google/protobuf/timestamp.proto";

option java_package = "com.google.pubsub.flic.common";
option java_outer_classname = "LoadtestProto";

service LoadtestWorker {
  // Starts a worker
  rpc Start (StartRequest) returns (StartResponse);

  // Check the status of a load test worker.
  rpc Check (CheckRequest) returns (CheckResponse);
}

message StartRequest {
  // The GCP project. This must be set even for Kafka, as we use it to export metrics.
  string project = 1;

  // The Pub/Sub or Kafka topic name.
  string topic = 2;

  // The time at which the load test should start. If this is less than the current time, we start immediately.
  google.protobuf.Timestamp start_time = 3;

  // The duration the load test should run for.
  google.protobuf.Duration test_duration = 4;

  // Whether to include ids in check responses.
  bool include_ids = 5;

  oneof options {
    PubsubOptions pubsub_options = 6;
    KafkaOptions kafka_options = 7;
  }

  oneof client_options {
    PublisherOptions publisher_options = 8;
    SubscriberOptions subscriber_options = 9;
  }
}

message StartResponse {
}

message PublisherOptions {
  // The max messages-per-second publishing rate.  If unset, no rate limit will
  // be imposed.
  float rate = 1;
  // The max duration for coalescing a batch of published messages.
  google.protobuf.Duration batch_duration = 2;
  // The number of user messages of size message_size to publish together.
  int32 batch_size = 3;
  // The size in bytes of messages to publish
  int32 message_size = 4;
}

message SubscriberOptions {
}

message PubsubOptions {
  // The Cloud Pub/Sub subscription name
  string subscription = 1;
}

message KafkaOptions {
  // The network address of the Kafka broker.
  string broker = 1;

  // The length of time to poll for.
  google.protobuf.Duration poll_duration = 2;

  // The network address(es) of the Zookeeper host(s).
  string zookeeper_ip_address = 3;

  // The replication factor of the Kafka topic.
  int32 replication_factor = 4;

  // The number of partitions of the Kafka topic.
  int32 partitions = 5;
}

message MessageIdentifier {
  // The unique id of the client that published the message.
  int64 publisher_client_id = 1;

  // Sequence number of the published message with the given publish_client_id.
  int32 sequence_number = 2;
}

// A message for kafka which does not support adding metadata to the message.
message KafkaMessage {
  MessageIdentifier id = 1;
  google.protobuf.Timestamp publish_time = 2;
  bytes payload = 3;
}

// Request a statistics update.
message CheckRequest {}

message CheckResponse {
  // Histogram of latencies, each one a delta from the previous CheckResponse sent.
  // The bounds of the nth bucket (starting from the 0th bucket) are
  // [1.5^(n-1), 1.5^n) milliseconds.  The lower bound of the 0th bucket is 0 seconds.
  repeated int64 bucket_values = 1;

  // The duration from the start of the loadtest to its completion or now if is_finished is false.
  google.protobuf.Duration running_duration = 2;

  // True if the load test has finished running.
  bool is_finished = 3;

  // MessageIdentifiers of all received messages since the last Check.
  repeated MessageIdentifier received_messages = 4;
}
